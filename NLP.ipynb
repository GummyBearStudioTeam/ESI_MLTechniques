{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kENXF_vPOrD7",
    "outputId": "e447adc0-5bbf-4d07-f299-5ff1d5d1c026"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gbs/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/gbs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/gbs/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/gbs/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.corpus\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import seaborn as sns\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NazHONfiVqED"
   },
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DUSxKRnOU3y"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "X9l7NB9VLh1s"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labeled_data.csv\")\n",
    "df.drop(df.columns[0], inplace=True, axis=1)\n",
    "hatred_dict = pd.read_csv(\"refined_ngram_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44Th0QTQ90sL",
    "outputId": "df53936f-535d-47ff-83f8-f1d0de81ab91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "0          3            0                   0        3      2   \n",
       "1          3            0                   3        0      1   \n",
       "2          3            0                   3        0      1   \n",
       "3          3            0                   2        1      1   \n",
       "4          6            0                   6        0      1   \n",
       "...      ...          ...                 ...      ...    ...   \n",
       "24778      3            0                   2        1      1   \n",
       "24779      3            0                   1        2      2   \n",
       "24780      3            0                   3        0      1   \n",
       "24781      6            0                   6        0      1   \n",
       "24782      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>prophate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allah akbar</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blacks</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chink</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chinks</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dykes</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>nigga you a lame</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>niggers are in my</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>wit a lame nigga</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>you a lame bitch</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>you fuck wit a</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ngram  prophate\n",
       "0          allah akbar     0.870\n",
       "1               blacks     0.583\n",
       "2                chink     0.467\n",
       "3               chinks     0.542\n",
       "4                dykes     0.602\n",
       "..                 ...       ...\n",
       "173   nigga you a lame     0.556\n",
       "174  niggers are in my     0.714\n",
       "175   wit a lame nigga     0.556\n",
       "176   you a lame bitch     0.556\n",
       "177     you fuck wit a     0.556\n",
       "\n",
       "[178 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fObzoThITjB3",
    "outputId": "6e1bf5db-aa20-4315-ff8b-d0870cd25d77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                 0\n",
       "hate_speech           0\n",
       "offensive_language    0\n",
       "neither               0\n",
       "class                 0\n",
       "tweet                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdsNfCLD94QD",
    "outputId": "e9074fff-e631-4d97-8d2d-8eef428cea6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.243473</td>\n",
       "      <td>0.280515</td>\n",
       "      <td>2.413711</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>1.110277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.883060</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>1.399459</td>\n",
       "      <td>1.113299</td>\n",
       "      <td>0.462089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count   hate_speech  offensive_language       neither  \\\n",
       "count  24783.000000  24783.000000        24783.000000  24783.000000   \n",
       "mean       3.243473      0.280515            2.413711      0.549247   \n",
       "std        0.883060      0.631851            1.399459      1.113299   \n",
       "min        3.000000      0.000000            0.000000      0.000000   \n",
       "25%        3.000000      0.000000            2.000000      0.000000   \n",
       "50%        3.000000      0.000000            3.000000      0.000000   \n",
       "75%        3.000000      0.000000            3.000000      0.000000   \n",
       "max        9.000000      7.000000            9.000000      9.000000   \n",
       "\n",
       "              class  \n",
       "count  24783.000000  \n",
       "mean       1.110277  \n",
       "std        0.462089  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        2.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCrAY6mOOdOM"
   },
   "source": [
    "## Correcting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "28ygMggGOPdp"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_words(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "class WordCorrector:\n",
    "\n",
    "    WORDS = Counter(get_words(open('big.txt').read()))\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "  ## TODO\n",
    "    def correct_text(self, text):\n",
    "        words = get_words(text)\n",
    "\n",
    "  #WORDS = Counter(words(open('big.txt').read())\n",
    "    def P(self, word, N=sum(WORDS.values())): \n",
    "        \"Probability of `word`.\"\n",
    "        return WORDS[word] / N\n",
    "\n",
    "    def correction(self, word): \n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(candidates(word), key=P)\n",
    "\n",
    "    def candidates(self, word): \n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "    def known(self, words): \n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in WORDS)\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "  \n",
    "    def edits2(self, word): \n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GnqAk20H47d"
   },
   "source": [
    "## Cleaning tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "fhB7nhDMH8vl"
   },
   "outputs": [],
   "source": [
    "special_characters_regex = '[!\"_$%&/()=_ˆ*¡@]'\n",
    "retweet_regex = '(.*rt @\\w+)+:'\n",
    "space_regex = '\\s+'\n",
    "url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "             '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "mention_regex = '@[\\w\\-]+'\n",
    "number_regex = '\\d+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "fhB7nhDMH8vl"
   },
   "outputs": [],
   "source": [
    "data_set = pd.DataFrame()\n",
    "data_set['clean'] = df['tweet']\n",
    "data_set['clean'] = data_set.apply(lambda row:\n",
    "                        re.sub(space_regex, ' ',\n",
    "                        re.sub(special_characters_regex, '', \n",
    "                        re.sub(number_regex, ' NUMBERHERE ',\n",
    "                        re.sub('\\s*RT MENTIONHERE', ' MENTIONHERE ',\n",
    "                        re.sub(url_regex, ' LINKHERE ',\n",
    "                        re.sub(mention_regex, ' MENTIONHERE ',\n",
    "                        re.sub(retweet_regex, '',\n",
    "                        re.sub(space_regex, ' ',\n",
    "                              row['clean'])))))), flags=re.ASCII)), axis=1)\n",
    "\n",
    "data_set['clean'] = data_set.apply(lambda row: row['clean'].lower(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "fhB7nhDMH8vl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you's a muthafin lie # numberhere ; mentionhere : mentionhere mentionhere right his tl is trash # numberhere ;. now, mine? bible scriptures and hymns# numberhere ;\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set['clean'][24778]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you's a muthaf***in lie &#8220;@LifeAsKing: @20_Pearls @corey_emanuel right! His TL is trash &#8230;. Now, mine? Bible scriptures and hymns&#8221;\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][24778]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiting processed data\n",
    "To reduce memory usage a data limit can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "yHRu4PRQ7BMi"
   },
   "outputs": [],
   "source": [
    "if N is not None:\n",
    "    data_set = data_set[0:N]\n",
    "    df = df[0:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup working sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "zeof13oPxGO5"
   },
   "outputs": [],
   "source": [
    "y = df[['class']]\n",
    "X = pd.DataFrame() #df[['hate_speech', 'offensive_language', 'neither']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1v3o8k_LcJi"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "-AOni-T8LEBq"
   },
   "outputs": [],
   "source": [
    "sentences = data_set.apply(lambda row: sent_tokenize(row['clean']),axis=1)\n",
    "words = data_set.apply(lambda row: word_tokenize(row['clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKKo7WxjOGI-",
    "outputId": "af8c5c3f-7414-4cc6-ab02-d9b41313ff12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [rt, mentionhere, :, woman, n't, complain, cle...\n",
       "1        [rt, mentionhere, :, boy, dats, cold, ..., tyg...\n",
       "2        [rt, mentionhere, dawg, rt, mentionhere, :, ev...\n",
       "3        [rt, mentionhere, :, mentionhere, look, like, ...\n",
       "4        [rt, mentionhere, :, shit, hear, might, true, ...\n",
       "                               ...                        \n",
       "24778    ['s, muthafin, lie, #, numberhere, mentionhere...\n",
       "24779    ['ve, gone, broke, wrong, heart, baby, drove, ...\n",
       "24780    [young, buck, wan, na, eat.., dat, nigguh, lik...\n",
       "24781             [youu, got, wild, bitches, tellin, lies]\n",
       "24782    [~~ruffled, |, ntac, eileen, dahlia, -, beauti...\n",
       "Name: clean, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords += [',', '.', ';']\n",
    "data_set['clean'] = words.apply(lambda row: [w for w in row if w not in stopwords]) \n",
    "data_set['clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25O89_lgWAHz"
   },
   "source": [
    "# 2. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "lmK81KSN8h0b"
   },
   "outputs": [],
   "source": [
    "joined = data_set.apply(lambda row: ' '.join(row['clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "lmK81KSN8h0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        rt mentionhere : woman n't complain cleaning h...\n",
       "1        rt mentionhere : boy dats cold ... tyga dwn ba...\n",
       "2        rt mentionhere dawg rt mentionhere : ever fuck...\n",
       "3            rt mentionhere : mentionhere look like tranny\n",
       "4        rt mentionhere : shit hear might true might fa...\n",
       "                               ...                        \n",
       "24778    's muthafin lie # numberhere mentionhere : men...\n",
       "24779    've gone broke wrong heart baby drove redneck ...\n",
       "24780    young buck wan na eat.. dat nigguh like aint f...\n",
       "24781                    youu got wild bitches tellin lies\n",
       "24782    ~~ruffled | ntac eileen dahlia - beautiful col...\n",
       "Length: 24783, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lySCoviQHBvv"
   },
   "source": [
    "### TFiDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMVh1GlfFXbI",
    "outputId": "31b5e43e-858f-4cec-85b6-c664866f6789"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 20194)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "X_tf = vectorizer.fit_transform(joined)\n",
    "X_tf.column = vectorizer.get_feature_names()\n",
    "X_tf.toarray()[0]\n",
    "#X.column\n",
    "X_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaaaaaaaand',\n",
       " 'aaahhhhh',\n",
       " 'aahahah',\n",
       " 'aaliyah',\n",
       " 'aamp',\n",
       " 'aamu',\n",
       " 'aan',\n",
       " 'aap',\n",
       " 'aaron',\n",
       " 'aaronmacgruder',\n",
       " 'aaryn',\n",
       " 'ab',\n",
       " 'abandonado',\n",
       " 'abbey',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abde',\n",
       " 'abdelka',\n",
       " 'abduction',\n",
       " 'abdullah',\n",
       " 'abdurahman',\n",
       " 'abed',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abo',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'abouta',\n",
       " 'abouttime',\n",
       " 'above',\n",
       " 'abraham',\n",
       " 'abs',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absoluteyvile',\n",
       " 'absolved',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abu',\n",
       " 'abundance',\n",
       " 'abus',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'acab',\n",
       " 'academic',\n",
       " 'accelerated',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accessories',\n",
       " 'accessorize',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'accipiter',\n",
       " 'accipitridae',\n",
       " 'accnt',\n",
       " 'accolades',\n",
       " 'accompanied',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accountants',\n",
       " 'accounts',\n",
       " 'accountsgate',\n",
       " 'acct',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accustomed',\n",
       " 'acdc',\n",
       " 'ace',\n",
       " 'aceptar',\n",
       " 'aceves',\n",
       " 'ach',\n",
       " 'achieve',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'acid',\n",
       " 'ackin',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledging',\n",
       " 'acl',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acquire',\n",
       " 'acre',\n",
       " 'acres',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actrist',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adawg',\n",
       " 'adays',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adderall',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addin',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adept',\n",
       " 'adidas',\n",
       " 'adios',\n",
       " 'adjustment',\n",
       " 'administration',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'admirable',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'ado',\n",
       " 'adonnis',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adorable',\n",
       " 'adorbs',\n",
       " 'adrenaline',\n",
       " 'adressed',\n",
       " 'adrien',\n",
       " 'ads',\n",
       " 'adtr',\n",
       " 'adult',\n",
       " 'adultery',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancedwarfaredayzero',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advil',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advocate',\n",
       " 'ae',\n",
       " 'aerin',\n",
       " 'aero',\n",
       " 'aeropostale',\n",
       " 'aeros',\n",
       " 'aerosmith',\n",
       " 'aerosolized',\n",
       " 'aesthetic',\n",
       " 'af',\n",
       " 'afc',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affects',\n",
       " 'affiliation',\n",
       " 'affleck',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afghanistan',\n",
       " 'afi',\n",
       " 'afl',\n",
       " 'aflcio',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'afrotino',\n",
       " 'afta',\n",
       " 'afterearth',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'aftertaste',\n",
       " 'afterwards',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agegt',\n",
       " 'agen',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'ages',\n",
       " 'agg',\n",
       " 'aggravating',\n",
       " 'aggressive',\n",
       " 'aghh',\n",
       " 'agholor',\n",
       " 'agitprop',\n",
       " 'agnes',\n",
       " 'ago',\n",
       " 'agony',\n",
       " 'agoooo',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agronomist',\n",
       " 'agru',\n",
       " 'ags',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahaaaa',\n",
       " 'ahaaaaa',\n",
       " 'ahah',\n",
       " 'ahaha',\n",
       " 'ahahahaa',\n",
       " 'ahahahha',\n",
       " 'ahahahhping',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahha',\n",
       " 'ahhh',\n",
       " 'ahhhahahaha',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahhi',\n",
       " 'ahl',\n",
       " 'ahmed',\n",
       " 'ahmesehwetnesslt',\n",
       " 'ahora',\n",
       " 'ahoy',\n",
       " 'ahs',\n",
       " 'ahsfreakshow',\n",
       " 'ahve',\n",
       " 'ai',\n",
       " 'aicha',\n",
       " 'aid',\n",
       " 'aidcpr',\n",
       " 'aide',\n",
       " 'aids',\n",
       " 'aight',\n",
       " 'aiko',\n",
       " 'aim',\n",
       " 'ainn',\n",
       " 'ainna',\n",
       " 'ainnn',\n",
       " 'aint',\n",
       " 'aintnobread',\n",
       " 'aintnolevelz',\n",
       " 'air',\n",
       " 'airbag',\n",
       " 'aired',\n",
       " 'airing',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airs',\n",
       " 'ajay',\n",
       " 'ajmi',\n",
       " 'ajumma',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'aklve',\n",
       " 'aktin',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alabamian',\n",
       " 'aladdin',\n",
       " 'alanah',\n",
       " 'alarm',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alberta',\n",
       " 'alberto',\n",
       " 'albino',\n",
       " 'albinos',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alchohol',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alcs',\n",
       " 'alec',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexfromtarget',\n",
       " 'alexi',\n",
       " 'alfie',\n",
       " 'alfredo',\n",
       " 'alg',\n",
       " 'algebra',\n",
       " 'algeria',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'alibaba',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'alla',\n",
       " 'allah',\n",
       " 'allahs',\n",
       " 'allbad',\n",
       " 'alledged',\n",
       " 'alleen',\n",
       " 'allegations',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allen',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'alley',\n",
       " 'allezwiggo',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'alligator',\n",
       " 'allisons',\n",
       " 'alliterationtuesday',\n",
       " 'alll',\n",
       " 'allll',\n",
       " 'alllll',\n",
       " 'allllll',\n",
       " 'allllllll',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowin',\n",
       " 'allowing',\n",
       " 'alls',\n",
       " 'allstar',\n",
       " 'allure',\n",
       " 'allusion',\n",
       " 'ally',\n",
       " 'almeria',\n",
       " 'almighty',\n",
       " 'almightydavehunna',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'aloha',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alot',\n",
       " 'alotta',\n",
       " 'aloud',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alqueda',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'als',\n",
       " 'alsarabsss',\n",
       " 'alsina',\n",
       " 'also',\n",
       " 'alsonobeermoney',\n",
       " 'alt',\n",
       " 'altar',\n",
       " 'alternate',\n",
       " 'althea',\n",
       " 'although',\n",
       " 'altyd',\n",
       " 'alu',\n",
       " 'aluminum',\n",
       " 'alves',\n",
       " 'alway',\n",
       " 'always',\n",
       " 'alwaysonwatch',\n",
       " 'alweer',\n",
       " 'alyssa',\n",
       " 'alzheimer',\n",
       " 'am',\n",
       " 'amanda',\n",
       " 'amar',\n",
       " 'amaris',\n",
       " 'amarte',\n",
       " 'amas',\n",
       " 'amateur',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazi',\n",
       " 'amazin',\n",
       " 'amazing',\n",
       " 'amazingtiming',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'ambulance',\n",
       " 'amcon',\n",
       " 'amcwalkingdead',\n",
       " 'amediting',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'amendment',\n",
       " 'amennn',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanized',\n",
       " 'americanmasters',\n",
       " 'americans',\n",
       " 'americarna',\n",
       " 'americaspasttime',\n",
       " 'amex',\n",
       " 'amg',\n",
       " 'amici',\n",
       " 'amigo',\n",
       " 'amina',\n",
       " 'aminfairview',\n",
       " 'amirite',\n",
       " 'amish',\n",
       " 'ammendment',\n",
       " 'ammo',\n",
       " 'amnesty',\n",
       " 'amo',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amos',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amped',\n",
       " 'amphibians',\n",
       " 'amsterdam',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amwriting',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anaconda',\n",
       " 'anacortes',\n",
       " 'anal',\n",
       " 'analysis',\n",
       " 'analyzer',\n",
       " 'analyzing',\n",
       " 'ananconda',\n",
       " 'anand',\n",
       " 'anarchism',\n",
       " 'anarchists',\n",
       " 'anarcho',\n",
       " 'anarchy',\n",
       " 'anat',\n",
       " 'anathema',\n",
       " 'anaya',\n",
       " 'anbar',\n",
       " 'ancestor',\n",
       " 'anchor',\n",
       " 'anchorrope',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'andbeating',\n",
       " 'andcounting',\n",
       " 'anderson',\n",
       " 'andlovinit',\n",
       " 'andnowihaveebola',\n",
       " 'andor',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'andrewbryant',\n",
       " 'andrews',\n",
       " 'android',\n",
       " 'andy',\n",
       " 'ane',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angelic',\n",
       " 'angelique',\n",
       " 'angelo',\n",
       " 'angelou',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'anglo',\n",
       " 'angola',\n",
       " 'angry',\n",
       " 'angus',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'anime',\n",
       " 'animosity',\n",
       " 'ankh',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'ann',\n",
       " 'annabella',\n",
       " 'annabelle',\n",
       " 'annalise',\n",
       " 'anncoulter',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'annis',\n",
       " 'anniversary',\n",
       " 'annnie',\n",
       " 'annnnd',\n",
       " 'annouced',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcers',\n",
       " 'announcing',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'anon',\n",
       " 'anoniemeaso',\n",
       " 'anonymous',\n",
       " 'anorexic',\n",
       " 'anotha',\n",
       " 'another',\n",
       " 'anoyin',\n",
       " 'answer',\n",
       " 'answerd',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'anthem',\n",
       " 'anthems',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antics',\n",
       " 'antigun',\n",
       " 'antisemite',\n",
       " 'antisemitism',\n",
       " 'antonio',\n",
       " 'antony',\n",
       " 'antville',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyday',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyones',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anywaaaaaays',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywere',\n",
       " 'anywhere',\n",
       " 'ao',\n",
       " 'aoas',\n",
       " 'aob',\n",
       " 'aone',\n",
       " 'ap',\n",
       " 'apache',\n",
       " 'apaches',\n",
       " 'apart',\n",
       " 'apartheid',\n",
       " 'apartment',\n",
       " 'ape',\n",
       " 'apersec',\n",
       " 'apes',\n",
       " 'apex',\n",
       " 'apka',\n",
       " 'apocalypse',\n",
       " 'apollo',\n",
       " 'apologies',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apolonia',\n",
       " 'apolonio',\n",
       " 'apostate',\n",
       " 'apostles',\n",
       " 'app',\n",
       " 'apparel',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appetite',\n",
       " 'applaud',\n",
       " 'applauding',\n",
       " 'apple',\n",
       " 'applebee',\n",
       " 'applebees',\n",
       " 'apples',\n",
       " 'applewood',\n",
       " 'appliances',\n",
       " 'application',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appointed',\n",
       " 'appointee',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciating',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approximately',\n",
       " 'approximating',\n",
       " 'apr',\n",
       " 'apracecall',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aq',\n",
       " 'aqsa',\n",
       " 'aqua',\n",
       " 'aquafina',\n",
       " 'aquarium',\n",
       " 'aquatic',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabic',\n",
       " 'arabspring',\n",
       " 'arafa',\n",
       " 'arc',\n",
       " 'arcade',\n",
       " 'arches',\n",
       " 'archives',\n",
       " 'arduino',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'arent',\n",
       " 'aretha',\n",
       " 'argentina',\n",
       " 'argentino',\n",
       " 'argie',\n",
       " 'argue',\n",
       " 'arguement',\n",
       " 'arguin',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'argurment',\n",
       " 'argus',\n",
       " 'ari',\n",
       " 'arial',\n",
       " 'ariana',\n",
       " 'aries',\n",
       " 'ariza',\n",
       " 'arizona',\n",
       " 'arkansas',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'armisticeday',\n",
       " 'armo',\n",
       " 'armor',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arnt',\n",
       " 'arod',\n",
       " 'around',\n",
       " 'aroundddd',\n",
       " 'arples',\n",
       " 'arranged',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arresting',\n",
       " 'arrests',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'arrows',\n",
       " 'arroz',\n",
       " 'arrsted',\n",
       " 'ars',\n",
       " 'arse',\n",
       " 'arsed',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'artichoke',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artists',\n",
       " 'artprize',\n",
       " 'arturo',\n",
       " 'aryan',\n",
       " 'as',\n",
       " 'asa',\n",
       " 'asada',\n",
       " 'asadita',\n",
       " 'asagiraffes',\n",
       " 'asains',\n",
       " 'asaka',\n",
       " 'asap',\n",
       " 'ascii',\n",
       " 'asco',\n",
       " 'asf',\n",
       " 'asfck',\n",
       " 'ash',\n",
       " 'asha',\n",
       " 'ashamed',\n",
       " 'ashanti',\n",
       " 'ashit',\n",
       " 'ashley',\n",
       " 'ashton',\n",
       " 'ashtray',\n",
       " 'ashy',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asians',\n",
       " 'aside',\n",
       " 'asidebitchmadethis',\n",
       " 'asides',\n",
       " 'asik',\n",
       " 'asinine',\n",
       " 'ask',\n",
       " 'askaugust',\n",
       " 'askd',\n",
       " 'askdems',\n",
       " 'askdrmann',\n",
       " 'aske',\n",
       " 'asked',\n",
       " 'askedanswering',\n",
       " 'askim',\n",
       " 'askin',\n",
       " 'asking',\n",
       " 'askkevin',\n",
       " 'asks',\n",
       " 'asl',\n",
       " 'asleep',\n",
       " 'aslina',\n",
       " 'asmsg',\n",
       " 'asphalt',\n",
       " 'aspirations',\n",
       " 'aspiring',\n",
       " 'ass',\n",
       " 'assassinate',\n",
       " 'assault',\n",
       " 'assaulting',\n",
       " 'assed',\n",
       " 'assemblywoman',\n",
       " 'asserted',\n",
       " 'asses',\n",
       " 'assets',\n",
       " 'asshat',\n",
       " 'asshats',\n",
       " 'asshole',\n",
       " 'assholeoftheyear',\n",
       " 'assholes',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assistance',\n",
       " 'assless',\n",
       " 'assness',\n",
       " 'assoc',\n",
       " 'associate',\n",
       " 'associates',\n",
       " 'association',\n",
       " 'asss',\n",
       " 'asssofathairsoreal',\n",
       " 'assss',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumptions',\n",
       " 'assure',\n",
       " 'assyria',\n",
       " 'assyrian',\n",
       " 'ast',\n",
       " 'asthma',\n",
       " 'astigmatisms',\n",
       " 'astrology',\n",
       " 'astronaut',\n",
       " 'astros',\n",
       " 'asvab',\n",
       " 'asylum',\n",
       " 'at',\n",
       " 'atamp',\n",
       " 'atcha',\n",
       " 'atcq',\n",
       " 'ate',\n",
       " 'ateam',\n",
       " 'atf',\n",
       " 'atg',\n",
       " 'athea',\n",
       " 'atheist',\n",
       " 'athem',\n",
       " 'athlete',\n",
       " 'athletes',\n",
       " 'athletic',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atom',\n",
       " 'atomic',\n",
       " 'atop',\n",
       " 'atound',\n",
       " 'atracciones',\n",
       " 'atrapaba',\n",
       " 'atrocities',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attackoftitan',\n",
       " 'attacks',\n",
       " 'attainable',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attendance',\n",
       " 'attendants',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attest',\n",
       " 'attire',\n",
       " 'attitud',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attn',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attribute',\n",
       " 'atunga',\n",
       " 'atysyc',\n",
       " 'aubreyjimmy',\n",
       " 'auburn',\n",
       " 'auburnnn',\n",
       " 'audacity',\n",
       " 'audible',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audition',\n",
       " 'auditioned',\n",
       " 'auditions',\n",
       " 'auditorium',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'auntie',\n",
       " 'aunts',\n",
       " 'auramea',\n",
       " 'aurora',\n",
       " 'ausmus',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'authentic',\n",
       " 'authenticity',\n",
       " 'authority',\n",
       " 'autistic',\n",
       " 'auto',\n",
       " 'autocorrect',\n",
       " 'autograph',\n",
       " 'autographed',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autopsies',\n",
       " 'autozone',\n",
       " 'autumn',\n",
       " 'aux',\n",
       " 'av',\n",
       " 'avail',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'ave',\n",
       " 'avengers',\n",
       " 'average',\n",
       " 'avery',\n",
       " 'avg',\n",
       " 'avi',\n",
       " 'avila',\n",
       " 'avis',\n",
       " 'avoid',\n",
       " 'avoiding',\n",
       " 'aw',\n",
       " 'awaaaaay',\n",
       " 'awad',\n",
       " 'awaiting',\n",
       " 'awaits',\n",
       " 'awake',\n",
       " 'awakening',\n",
       " 'award',\n",
       " 'awarde',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awb',\n",
       " 'awe',\n",
       " 'awee',\n",
       " 'awesome',\n",
       " 'awesomeness',\n",
       " 'awf',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awfy',\n",
       " 'awhile',\n",
       " 'awk',\n",
       " 'awkward',\n",
       " 'awnser',\n",
       " 'awoke',\n",
       " 'aww',\n",
       " 'awwe',\n",
       " 'awwsome',\n",
       " 'awww',\n",
       " 'awwww',\n",
       " 'awwwwe',\n",
       " 'awwwww',\n",
       " 'awwwwwesomeeeeee',\n",
       " 'awwwwww',\n",
       " 'ax',\n",
       " 'axe',\n",
       " 'axes',\n",
       " 'axin',\n",
       " 'axl',\n",
       " 'ay',\n",
       " 'aye',\n",
       " 'ayee',\n",
       " 'ayeee',\n",
       " 'ayeeee',\n",
       " 'ayeeeee',\n",
       " ...]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf.column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Sbad0IWHGGP"
   },
   "source": [
    "### TFiDF + N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZwZLemXDJJk",
    "outputId": "cc062848-7dc6-45b9-9d81-42368c9d5bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 284374)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,3), min_df=1)\n",
    "X_ngram = vectorizer.fit_transform(joined)\n",
    "X_ngram.column = vectorizer.get_feature_names()\n",
    "X_ngram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4.11697954],\n",
       "        [4.57417871],\n",
       "        [3.85030167],\n",
       "        ...,\n",
       "        [4.32662778],\n",
       "        [2.99912563],\n",
       "        [4.99870262]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngram.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnlnj_DSHIsT"
   },
   "source": [
    "### TFiDF + N-grams + POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MdhGYTFfAtg",
    "outputId": "0729505d-2650-4463-93cf-b73d6cd6beaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [(mentionhere, RB), (:, :), (woman, NN), (n't,...\n",
       "1        [(mentionhere, RB), (:, :), (boy, NN), (dats, ...\n",
       "2        [(mentionhere, RB), (dawgmentionhere, RB), (:,...\n",
       "3        [(mentionhere, RB), (:, :), (mentionhere, JJ),...\n",
       "4        [(mentionhere, RB), (:, :), (shit, JJ), (hear,...\n",
       "                               ...                        \n",
       "24778    [('s, POS), (muthafin, NN), (lie, NN), (#, #),...\n",
       "24779    [('ve, VBP), (gone, VBN), (broke, VBD), (wrong...\n",
       "24780    [(young, JJ), (buck, NN), (wan, WP), (na, TO),...\n",
       "24781    [(youu, NN), (got, VBD), (wild, JJ), (bitches,...\n",
       "24782    [(~~ruffled, VBN), (|, JJ), (ntac, NN), (eilee...\n",
       "Name: clean, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = data_set['clean'].apply(nltk.pos_tag)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C9Ap1rsHNa6"
   },
   "source": [
    "### Other Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jTAeVNEJXI6"
   },
   "source": [
    "#### RTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ayPzlxtRJWqS"
   },
   "outputs": [],
   "source": [
    "X['RT'] = df.apply(lambda row: row[\"tweet\"].count(\"RT\") , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsEHbtXIMzVI"
   },
   "source": [
    "#### Number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7JA26kaMykj",
    "outputId": "3a06c3ac-b73e-4426-cb88-7be433e2d8b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RT           0\n",
       "num_words    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['num_words'] = words.apply(len)\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7bU2ZJSNXHg"
   },
   "source": [
    "#### Number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bay_BUQNZdP",
    "outputId": "0e4c4d19-3c30-4930-f2d9-322a0e97a3eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RT           0\n",
       "num_words    0\n",
       "num_sents    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['num_sents'] = sentences.apply(len)\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RT  num_words  num_sents\n",
       "0       1         28          2\n",
       "1       1         17          1\n",
       "2       2         19          2\n",
       "3       1          8          1\n",
       "4       1         27          1\n",
       "...    ..        ...        ...\n",
       "24778   0         32          3\n",
       "24779   0         15          1\n",
       "24780   0         14          1\n",
       "24781   0          7          1\n",
       "24782   0         22          2\n",
       "\n",
       "[24783 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQTNHAl2P_7-"
   },
   "source": [
    "#### Sentiment analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZbN-nQtP-4N",
    "outputId": "e9f18b22-7204-4d3f-916d-1fd49c4aba1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RT           0\n",
       "num_words    0\n",
       "num_sents    0\n",
       "neg          0\n",
       "neu          0\n",
       "pos          0\n",
       "compound     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analyzer  = SentimentIntensityAnalyzer() \n",
    "sentiment = joined.apply(lambda row: sentiment_analyzer.polarity_scores(row))\n",
    "sentiment = pd.DataFrame.from_records(sentiment)\n",
    "if not any(c == 'neg' for c in X.columns):\n",
    "    X = pd.concat([X, sentiment], axis=1)\n",
    "else:\n",
    "    X.update(sentiment)\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oszfi3TrrKB8"
   },
   "source": [
    "#### Hatred n-gram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "vWBiO3EgrLmQ"
   },
   "outputs": [],
   "source": [
    "def get_weight(row):\n",
    "    return max(hd['prophate'] if hd['ngram'] in row else 0 for i,hd in hatred_dict.iterrows())\n",
    "\n",
    "X['hatedict'] = joined.apply(get_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761.939, 0.912)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['hatedict'].sum(), X['hatedict'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THJu41sRrRGY",
    "outputId": "37a53f2c-c613-41a5-8997-9f186785b203"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>hatedict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.309406</td>\n",
       "      <td>17.413065</td>\n",
       "      <td>1.293064</td>\n",
       "      <td>0.282205</td>\n",
       "      <td>0.597271</td>\n",
       "      <td>0.120527</td>\n",
       "      <td>-0.255822</td>\n",
       "      <td>0.030744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.510383</td>\n",
       "      <td>9.872397</td>\n",
       "      <td>0.687063</td>\n",
       "      <td>0.241840</td>\n",
       "      <td>0.247234</td>\n",
       "      <td>0.158440</td>\n",
       "      <td>0.478881</td>\n",
       "      <td>0.132205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.991600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.648600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>0.990600</td>\n",
       "      <td>0.912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RT     num_words     num_sents           neg           neu  \\\n",
       "count  24783.000000  24783.000000  24783.000000  24783.000000  24783.000000   \n",
       "mean       0.309406     17.413065      1.293064      0.282205      0.597271   \n",
       "std        0.510383      9.872397      0.687063      0.241840      0.247234   \n",
       "min        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%        0.000000     10.000000      1.000000      0.000000      0.417000   \n",
       "50%        0.000000     16.000000      1.000000      0.283000      0.571000   \n",
       "75%        1.000000     24.000000      1.000000      0.458000      0.759000   \n",
       "max        4.000000    241.000000     42.000000      1.000000      1.000000   \n",
       "\n",
       "                pos      compound      hatedict  \n",
       "count  24783.000000  24783.000000  24783.000000  \n",
       "mean       0.120527     -0.255822      0.030744  \n",
       "std        0.158440      0.478881      0.132205  \n",
       "min        0.000000     -0.991600      0.000000  \n",
       "25%        0.000000     -0.648600      0.000000  \n",
       "50%        0.000000     -0.340000      0.000000  \n",
       "75%        0.222000      0.000000      0.000000  \n",
       "max        0.891000      0.990600      0.912000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ASwJzr-WI4H"
   },
   "source": [
    "# 3. Feature selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "WU0NZXFK_Pps"
   },
   "source": [
    "'''from functools import reduce\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='constant', fill_value=0)\n",
    "imp.fit(X_tf)\n",
    "X_tf = imp.transform(X_tf)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "WU0NZXFK_Pps"
   },
   "outputs": [],
   "source": [
    "X_tf_df = pd.DataFrame.sparse.from_spmatrix(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 21517)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "mzfP2Uhm7wr2"
   },
   "outputs": [],
   "source": [
    "X = pd.concat([X, X_tf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWWIGNkQ-cAL",
    "outputId": "16b30138-2341-4a2a-f8f7-168876aba282"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>hatedict</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>21507</th>\n",
       "      <th>21508</th>\n",
       "      <th>21509</th>\n",
       "      <th>21510</th>\n",
       "      <th>21511</th>\n",
       "      <th>21512</th>\n",
       "      <th>21513</th>\n",
       "      <th>21514</th>\n",
       "      <th>21515</th>\n",
       "      <th>21516</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.6808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 21525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RT  num_words  num_sents    neg    neu    pos  compound  hatedict    0  \\\n",
       "0       1         28          2  0.000  0.839  0.161    0.2755       0.0  0.0   \n",
       "1       1         17          1  0.226  0.774  0.000   -0.5423       0.0  0.0   \n",
       "2       2         19          2  0.803  0.197  0.000   -0.9460       0.0  0.0   \n",
       "3       1          8          1  0.000  0.615  0.385    0.3612       0.0  0.0   \n",
       "4       1         27          1  0.407  0.440  0.154   -0.6808       0.0  0.0   \n",
       "...    ..        ...        ...    ...    ...    ...       ...       ...  ...   \n",
       "24778   0         32          3  0.000  1.000  0.000    0.0000       0.0  0.0   \n",
       "24779   0         15          1  0.580  0.420  0.000   -0.8074       0.0  0.0   \n",
       "24780   0         14          1  0.000  0.800  0.200    0.3612       0.0  0.0   \n",
       "24781   0          7          1  0.626  0.374  0.000   -0.7717       0.0  0.0   \n",
       "24782   0         22          2  0.000  0.769  0.231    0.5994       0.0  0.0   \n",
       "\n",
       "         1  ...  21507  21508  21509  21510  21511  21512  21513  21514  \\\n",
       "0      0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1      0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2      0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3      0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4      0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...    ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24778  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24779  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24780  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24781  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "24782  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       21515  21516  \n",
       "0        0.0    0.0  \n",
       "1        0.0    0.0  \n",
       "2        0.0    0.0  \n",
       "3        0.0    0.0  \n",
       "4        0.0    0.0  \n",
       "...      ...    ...  \n",
       "24778    0.0    0.0  \n",
       "24779    0.0    0.0  \n",
       "24780    0.0    0.0  \n",
       "24781    0.0    0.0  \n",
       "24782    0.0    0.0  \n",
       "\n",
       "[24783 rows x 21525 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EonJOIwa1XhO",
    "outputId": "b91bade1-5094-4aad-a42b-ead9dd15ec64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% of features: 21525\n",
      " 70% of features: 15068\n"
     ]
    }
   ],
   "source": [
    "size = len(X.columns)\n",
    "to_cut = ceil(0.7*len(X.columns))\n",
    "to_save = size - to_cut\n",
    "print('100% of features: {}\\n 70% of features: {}'.format(size, to_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMEU6b8P_eFB",
    "outputId": "d6abf12a-c3c5-4e8a-c344-6bce8df36c39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbs/.conda/envs/data/lib/python3.8/site-packages/sklearn/utils/validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-3e38057cbcc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \"\"\"\n\u001b[0;32m--> 344\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n\u001b[0m\u001b[1;32m    345\u001b[0m                                    multi_output=True)\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "\n",
    "selector = SelectKBest(f_regression, k=to_save)\n",
    "selector.fit(X, y)\n",
    "X_new = selector.transform(X)\n",
    "columns = list(X.columns[selector.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLdfYuIhWI-a",
    "outputId": "bd5de3e0-40cc-4f08-bb21-23d61dab6b33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_sents', 'neg', 'neu', 'pos', 'compound', 'hatedict', 0, 2, 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJtsa0X5WKlc"
   },
   "source": [
    "# 4. Classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6Tk7nPG-nGI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_new, y, random_state=2, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjihMjSa80uP"
   },
   "source": [
    "##Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPku1HpiHTd1"
   },
   "source": [
    "###Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WT4MP4yI6QmV",
    "outputId": "79b4308e-b0bc-4e61-d44d-94df427a0f55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model.fit(Xtrain, ytrain)\n",
    "ypred_forest = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr0e8dqKCEHQ"
   },
   "source": [
    "###Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "ER6ZfAFA8akT",
    "outputId": "e729cb23-b23b-4988-c417-e549860473e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36         4\n",
      "           1       1.00      0.82      0.90       282\n",
      "           2       0.25      0.93      0.40        14\n",
      "\n",
      "    accuracy                           0.83       300\n",
      "   macro avg       0.49      0.92      0.55       300\n",
      "weighted avg       0.95      0.83      0.87       300\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mat_forest = confusion_matrix(ytest, ypred_forest)\n",
    "sns.heatmap(mat_forest.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "print(metrics.classification_report(ypred_forest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sU-ygTOIBZpO",
    "outputId": "7fe0a0a8-9c53-4db1-907a-d6e3f5053794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266666666666667\n"
     ]
    }
   ],
   "source": [
    "forest_score = metrics.accuracy_score(ytest, ypred_forest)\n",
    "print(f'{forest_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsPEhjG48_L8"
   },
   "source": [
    "##Support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_smgjbmcHBO6",
    "outputId": "d5a1d55e-51e0-4a9b-e68d-4cf04d11fc41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svc = SVC(kernel='linear', C=1E10)\n",
    "model_svc.fit(Xtrain, ytrain)\n",
    "ypred_svm = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQVIb8nbIrem"
   },
   "source": [
    "###Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "2NbE0bEBItnB",
    "outputId": "0ac7a91b-ba1e-4ca4-c8e0-740b9ac83365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.36        18\n",
      "           1       0.82      1.00      0.90       231\n",
      "           2       0.93      0.25      0.40        51\n",
      "\n",
      "    accuracy                           0.83       300\n",
      "   macro avg       0.92      0.49      0.55       300\n",
      "weighted avg       0.85      0.83      0.78       300\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat_svm = confusion_matrix(ytest, ypred)\n",
    "sns.heatmap(mat_svc.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "print(metrics.classification_report(ytest, ypred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DziB5Bv8JPkK",
    "outputId": "1addcba5-4ee6-428c-9f63-c93f407d75be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7266666666666667\n"
     ]
    }
   ],
   "source": [
    "svm_score = metrics.accuracy_score(ytest, ypred)\n",
    "print(f'{svm_score}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
